# 第三章 爬虫和蜘蛛

> 作者：Gilberto Najera-Gutierrez

> 译者：[飞龙](https://github.com/)

> 协议：[CC BY-NC-SA 4.0](http://creativecommons.org/licenses/by-nc-sa/4.0/)

## 简介

渗透测试可以通过多种途径完成，例如黑盒、灰盒和白盒。黑盒测试在测试者没有任何应用的前置信息条件下执行，除了服务器的 URL。白盒测试在测试者拥有目标的全部信息的条件下执行，例如它的构造、软件版本、测试用户、开发信息，以及其它。灰盒测试是黑盒和白盒的混合。

对于黑盒和灰盒测试，侦查阶段对测试者非常必然，以便发现白盒测试中通常由应用所有者提供的信息。

我们打算采取黑盒测试方式，因为它涉及到外部攻击者用于获取足够信息的所有步骤，以便入侵应用或服务器的特定功能。

作为每个 Web 渗透测试中侦查阶段的一部分，我们需要浏览器每个包含在网页中的链接，并跟踪它展示的每个文件。有一些工具能够帮助我们自动和以及加速完成这个任务，它们叫做 Web 爬虫或蜘蛛。这些工具通过跟随所有到外部文件的链接和引用，有的时候会填充表单并将它们发送到服务器，保存所有请求和响应来浏览网页，从而提供给我们离线分析它们的机会。

这一章中，我们会涉及到一些包含在 Kali 中的爬虫的使用，也会查看我们感兴趣的文件和目录，来寻找常见的网页。

## 3.1 使用 Wget 为离线分析下载网页

Wget 是 GNU 项目的一部分，也包含在主流 linux 发行版中，包括 Kali。它能够递归为离线浏览下载网页，包括链接转换和下载非 HTML 文件。

这个秘籍中，我们会使用 Wget 来下载和 vulnerable_vm 中的应用相关的页面。

### 准备

这一章的所有秘籍都需要运行 vulnerable_vm。在这本书的特定场景中，它的 IP 地址为 192.168.56.102。

### 操作步骤

1.  让我们做第一次尝试，通过仅仅以一个参数调用 Wget 来下载页面。

    ```
    wget http://192.168.56.102/bodgeit/
    ```
    
    ![](img/3-1-1.jpg)
    
    我们可以看到，它仅仅下载了`index.html`文件到当前目录，这是应用的首页。
    
2.  我们需要使用一些选项，告诉 Wget 将所有下载的文件保存到特定目录中，并且复制我们设为参数的 URL 中包含的所有文件。让我们首先创建目录来保存这些文件：

    ```
    mkdir bodgeit_offline
    ```
    
3.  现在，我们会递归下载应用中所有文件并保存到相应目录中。

    ```
    wget -r -P bodgeit_offline/ http://192.168.56.102/bodgeit/

    ```
    
    ![](img/3-1-2.jpg)
    
### 工作原理

像之前提到的那样，Wget 是个为下载 HTTP 内容创建的工具。通过`-r`参数，我们可以使其递归下载，这会按照它所下载的每个页面的所有连接，并同样下载它们。`-P`选项允许我们设置目录前缀，这是 Wget 会开始保存下载内容的目录。默认它设为当前目录。

### 更多

在我们使用 Wget 时，可以考虑一些其它的实用选项：

+   `-l`：在递归下载的时候，规定 Wget 的遍历深度可能很有必要。这个选项后面带有我们想要遍历的层级深度的数值，让我们规定这样的界限。

+   `-k`：在文件下载之后，Wget 修改所有链接，使其指向相应的本地文件，这会使站点能够在本地浏览。

+   `-p`：这个选项让 Wget 下载页面所需的所有图像，即使它们位于其它站点。

+   `-w`：这个选项让 Wget 在两次下载之间等待指定的描述。当服务器中存在防止自动浏览的机制时，这会非常有用。
